{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Milestone 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "n0E3QosiFhTM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " # Milestone 1\n",
        " \n",
        " First milestone for CS207 Fall 2018 Project Group 1.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "BZQ9eSPOFrYQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ]
    },
    {
      "metadata": {
        "id": "wid16KxhFral",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Differentiation is ubiquitous in almost all aspects of computer science, mathematics, and physics. It is used for numeric root-finding as in Newton's Method, and used for optimization with different forms of gradient descent.\n",
        "However, calculating analytic derivatives is difficult and can lead to exponentially growing abstract syntax trees, which makes finding the derivative infeasible in many cases.\n",
        "Similarly, calculating the derivative numerically using the limit definition runs into numeric instabilities due to limited machine precision.\n",
        "Automatic differentiation addresses both of these issues - it uses the chain rule and the fact that computers calculate any function as a sequence of elementary operations to find the derivative."
      ]
    },
    {
      "metadata": {
        "id": "Q94IjE67FrdI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Background"
      ]
    },
    {
      "metadata": {
        "id": "r1STxfT9Frfl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Automatic differentiation relies heavily on the principles of chain rule differentiation. A graph of elementary functions is built to calculate the values of more complex functions. Using the chain rule on the graph of elementary functions, the value of the derivative at each node can also be calculated. This gives us the ability to calculate the values of functions and their derivatives, no matter how complex, to near machine precision (a significant advantage compared to alternatives such as finite differences). \n",
        "\n",
        "The chain rule tells us that:\n",
        "\\begin{align}\n",
        "\\frac{d}{dx}(f(g(x))) &= f'(g(x))g'(x)\\\\\n",
        "\\end{align}\n",
        "\n",
        "Since each step in our graph is just a combination of linear operations, we can find the derivative at a node by considering the value and derivative of the expressions at the previous node. By starting with an initial 'seed' vector for the derivative (often set to 1), we can find the derivative in any desired search direction. \n",
        "\n",
        "Below is an example of constructing a graph to find the exact values of a function and its derivative. The function we used was:\n",
        "\n",
        "$$f\\left(x, y, z\\right) = \\dfrac{1}{xyz} + \\sin\\left(\\dfrac{1}{x} + \\dfrac{1}{y} + \\dfrac{1}{z}\\right)$$\n",
        "\n",
        "We worked through this, starting with trace elements $x_1$ for $x$,  $x_2$ for $y$ and  $x_3$ for $z$. We wanted to solve this function at $(x, y, z) = (1, 2, 3)$.\n",
        "\n",
        "| Trace | Elementary Function | Current Value | Elementary Function Derivative | $\\nabla_{x}$ Value  | $\\nabla_{y}$ Value  | $\\nabla_{z}$ Value  |\n",
        "| :---: | :-----------------: | :-----------: | :----------------------------: | :-----------------: | :-----------------: | :-----------------: |\n",
        "| $x_{1}$ | $x$ | 1 | $\\dot{x}$ | 1 | 0 | 0 | \n",
        "| $x_{2}$ | $y$ | 2 | $\\dot{y}$ | 0 | 1 | 0 | \n",
        "| $x_{3}$ | $z$ | 3 | $\\dot{z}$ | 0 | 0 | 1 | \n",
        "| $x_{4}$ | $1/x_{1}$ | 1 | $-\\dot{x}_{1}/x_{1}^{2}$ | $-1$ | $0$ | $0$ | \n",
        "| $x_{5}$ | $1/x_{2}$ | 1/2 | $-\\dot{x}_{2}/x_{2}^{2}$ | $0$ | $-1/4$ | $0$ | \n",
        "| $x_{6}$ | $1/x_{3}$ | 1/3 |  $-\\dot{x}_{3}/x_{3}^{2}$ | $0$ | $0$ | $-1/9$ | \n",
        "| $x_{7}$ | $x_{4} + x_{5} + x_{6}$ | 11/6 |$\\dot{x}_{4} + \\dot{x}_{5} + \\dot{x}_{6}$ | -1 | -0.25 | -0.11 |\n",
        "| $x_{8}$ | $sin(x_{7})$ | 0.966 |$\\dot{x}_{7}cos(x_{7})$ | 0.260 | 0.065 | 0.029 | \n",
        "| $x_{9}$ | $x_{4}x_{5}x_{6}$| 1/6 |$\\dot{x}_{4}x_{5}x_{6} + \\dot{x}_{5}x_{4}x_{6} + \\dot{x}_{6}x_{4}x_{5} $ |-0.167 | -0.083  | -0.056 | \n",
        "| $x_{10}$ | $x_{8} + x_{9}$ | 1.132 |$\\dot{x}_{8} + \\dot{x}_{9}$ | 0.093| -0.018  | -0.027 | \n",
        "\n",
        "This isn't a very complicated function, but it shows how we can use the most basic of functions to create a graph allowing us to find exact values and gradients.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-5o9TDfWIotu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Usage"
      ]
    },
    {
      "metadata": {
        "id": "I3Kql6XHFruY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since most expressions and applications that require automatic differentiation are not constructed dynamically, we will start by building the computational graph statically. Then, to perform computations and get the derivative, we feed our computational graph some inputs. A sample usage would look like:\n",
        "\n",
        "```python\n",
        ">>> import ad\n",
        ">>> x = ad.Variable('x')\n",
        ">>> f = 10.0 + 5.0 * (x ** 2.0) - 3.0 * x\n",
        ">>> f.eval({'x': 5.0})\n",
        "120.0\n",
        ">>> f.d\n",
        "47.0\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "_zHpf8T-IvAl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Multiple inputs could also be provided. For example,\n",
        "\n",
        "```python\n",
        ">>> x = ad.Variable('x')\n",
        ">>> y = ad.Variable('y')\n",
        ">>> f = x * y\n",
        ">>> f.eval({'x': 5.0, 'y': 2.0})\n",
        "10.0\n",
        ">>> f.d\n",
        "{x: 2.0, y: 5.0}\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "hV1RqLyOFrwx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Software Organization"
      ]
    },
    {
      "metadata": {
        "id": "24dDqdkQF3dc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Directory Structure\n",
        "\n",
        "Our library currently only does Automatic Differentiation. Therefore, we only have one module, which we will call `ad`. We will add additional modules for our extension once we decide what we will be doing for that.\n",
        "\n",
        "```bash\n",
        "cs207project\n",
        "├── LICENSE\n",
        "├── README\n",
        "├── ad\n",
        "│   ├── __init__.py\n",
        "│   ├── ad.py\n",
        "│   ├── mat_ops.py\n",
        "│   ├── plots.py\n",
        "│   ├── simple_ops.py\n",
        "│   └── tests\n",
        "│       ├── test_eval.py\n",
        "│       ├── test_forward.py\n",
        "│       ├── test_mat_ops.py\n",
        "│       └── test_simple_ops.py\n",
        "└── setup.py\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "wVxWq3DQawMY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our test suite will use TravisCI for continual integration and Coveralls for testing code coverage. Also, we will distribute our package through PyPI."
      ]
    },
    {
      "metadata": {
        "id": "KgRtT_JtF_Bx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ]
    },
    {
      "metadata": {
        "id": "qGD8r-C5F_Ez",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In our implementation, “Expression\" would be the core data structure. Everything in the computational graph is an expression. "
      ]
    },
    {
      "metadata": {
        "id": "Z4QZ1zUNF3gI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The attributes of an expression includes its gradient and the links to its children. The methods of an expression includes \"eval\" (get the value of the expression) and \"d\" (get the gradient of the expression). Dunder methods like \\__add__(), \\__sub__(), \\__mul__(), and \\__truediv__()  will be implemented for ease of use."
      ]
    },
    {
      "metadata": {
        "id": "8ZWii9l8F_Lz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Classes that we are going to implement for constructing the computational graph include: \n",
        "\n",
        "* Expression(object)\n",
        "* Variable(Expression)\n",
        "* Constant(Expression)\n",
        "\n",
        "Classes that we will use for operations take in one or two instances of an `Expression` class and returns a new `Expression` class with the operation applied. These will store the children so we can traverse down our computational graph. The initial classes will be:\n",
        "\n",
        "* Unop(Expression)\n",
        "* Binop(Expression)\n",
        "* Addition(Binop)\n",
        "* Subtraction(Binop)\n",
        "* Multiplication(Binop)\n",
        "* Division(Binop)\n",
        "* Sin(Unop)\n",
        "* Cos(Unop)\n",
        "* Exp(Unop)\n",
        "* Log(Unop)\n",
        "\n",
        "The `Unop` class is a base class that stores 1 child and `Binop` stores two children. This implementation should be able to handle vector functions of vectors by using multiple `Variable` objects in our function."
      ]
    },
    {
      "metadata": {
        "id": "wCIKrJBRge5U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## External Dependencies\n",
        "\n",
        "We will mainly be using `numpy` as an external dependency for mathematical and vector operations."
      ]
    }
  ]
}